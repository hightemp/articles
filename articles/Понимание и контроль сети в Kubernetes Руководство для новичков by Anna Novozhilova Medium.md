# Понимание и контроль сети в Kubernetes: Руководство для новичков | by Anna Novozhilova | Medium
[

![](https://miro.medium.com/v2/resize:fill:44:44/1*zEHSPUqkLK2XUmQrHeS73g.jpeg)






](https://medium.com/@anny.nov41?source=post_page---byline--674e66e85071---------------------------------------)

![](https://miro.medium.com/v2/resize:fit:700/1*GIyxxaF8AfE6HCbnKkms5w.png)

Kubernetes — мощный инструмент для управления наборами контейнеров, и сети играют огромную роль в его работе. Сетевые инструменты обеспечивают обмен данными между объектами кластера, позволяют управлять нагрузкой и масштабированием, а также позволяют удаленным хостам получить доступ к ресурсам внутри кластера. Не будет преувеличением сказать, что без сетевого взаимодействия Kubernetes был бы практически бесполезен.

Тем не менее, понять то, как устроены сети в Kubernetes и осознать весь их потенциал начинающему пользователю довольно сложно. Еще совсем недавно я была точно таким же новичком (да и остаюсь им по сей день, если уж быть четсными), пытающимся не утонуть в море имеющейся информации. В этой статье я хочу изложить и систематизировать знания, которые мне удалось получить.

Когда перед тобой стоит большая и сложная задача, одной из лучших стратегий будет разделить ее на несколько поменьше. Так и поступим. Согласно официальной документации Kubernetes информацию о сетях в кластере можно разделить на 4 категории:

*   Высокосвязные коммуникации между контейнерами
*   Связность подов между собой
*   Связи между подами и сервисами
*   Связи между сервисами и внешними ресурсами

Воспользуемся этим делением, чтобы структурировать информацию.

**Container-to-container**
--------------------------

Несмотря на то, что Pod является самой маленькой развертываемой единицей в Kubernetes, он может содержать в себе больше одного контейнера. Такая ситуация уместна в том случае, если контейнеры обладают высокой связностью, например, регулярно используют одни и те же ресурсы или постоянно взаимодействуют между собой. Конечно, контейнерам необходимо иметь доступ друг к другу по сети, иначе не было бы и смысла размещать их внутри одного пода.

Связь между контейнерами внутри одного пода организована достаточно просто: они все делят между собой IP-адрес и доменное имя (такие же, как и у пода), пространство портов и средства синхронизации процессов (IPC namespace). Также есть возможность настроить Shared Volume для пода, чтобы все его контейнеры имели доступ к данным внутри тома.

Можно сказать, что контейнеры внутри пода взаимодействуют также, как процессы, выполняющиеся на одном сервере. Никаких дополнительных параметров в манифесте для их связи прописывать не нужно. Однако, при развертывании приложений внутри одного пода важно не забывать, что контейнеры не должны занимать один и тот же порт дважды (например, не должно быть ситуации, когда оба контейнера занимают для своих процессов 80 порт).

![](https://miro.medium.com/v2/resize:fit:271/1*qX3MZ87cfmAvLRjNdUQiLQ.png)

Container-to-container communication

**Pod-to-Pod**
--------------

Сложно точно сказать, как коммуницируют между собой поды в Kubernetes. Это связано с тем, что изначально Kubernetes не предлагает инструменты для сетевого взаимодействия, и основная работа с сетью осуществляется с помощью сторонних плагинов, реализующих стандарты CNI (Container Network Interface) и CRI (Container Runtime Interface). Первый отвечает за связь в кластере и ее настройку, а второй — за среду выполнения контейнеров. Самыми популярными CNI являются Calico и Flannel, а среди CRI выделяются docker engine, cri-o и containerd. Однако, в этой статье я не буду останавливаться подробно на каком-либо из плагинов, и сосредоточусь на общем принципе взаимодействия подов.

Каждому поду при создании присваивается IP-адрес в сети кластера, уникальный для этой сети, поэтому в самом простом варианте поды могут обращаться друг к другу по этим IP-адресам. Это свойство роднит их с виртуальными машинами. Так же поды могут открывать для доступа только определенные порты.

Проблема этого способа в том, что балансировка нагрузки в Kubernetes, ошибки работы и просто изменения конфигурации могут приводить к пересозданию пода и, как следствие, присваивание ему нового айпи-адреса. Более того, может возникнуть ситуация, когда подов, в которых работает одно и тоже приложение, может быть несколько, и вам хочется, чтобы все запросы к приложению равномерно распределялись между ними. В таких случаях обращение по IP-адресу становится неудобным, так как он в любой момент может стать неактуален.

Поэтому обычно для связи подов между собой используют сервисы. О том, что это и как это работает, я расскажу в следующем разделе.

![](https://miro.medium.com/v2/resize:fit:700/1*tWt0kY_DKrqoXdRVYZgZSw.png)

Pod-to-Service
--------------

Итак, сервис — это ресурс в Kubernetes, создающий единую точку входа для траффика, предназначенного для одного или нескольких подов. Сервисы позволяют обращаться к ресурсам в подах по единому IP-адресу или доменному имени, не задумываясь над тем, какой именно под получит этот запрос. Даже если в какой-то момент времени под будет пересоздан, адрес, к которому могут обращаться другие приложения, не изменится.

Простейший манифест для создания сервиса выглядит следующим образом:

```
apiVersion: v1  
kind: Service  
metadata:  
  name: my-service  
spec:  
  selector:  
    app.kubernetes.io/name: my-app  
  ports:  
    \- protocol: TCP  
      port: 80  
      targetPort: 9376
```

Этот манифест создаст сервис с именем my-service, который будет работать с любым подом, у которого есть лейбл app.kubernetes.io/name=my-app (принцип, по которому поды попадают в выборку назначается в разделе selector). Этот сервис сделает приложения, которые работают в этих подах на порту 9376, доступными через 80-тый порт.

Сервисы соединяются с подами с помощью EndpointSlices. Это ресурс в кластере Kubernetes, который обозначает одну или несколько конечных точек в сети и их связь с определенным сервисом. Каждый EndpointSlice может содержать в себе указание максимум на 100 конечных точек по умолчанию, и максимум на 1000 при изменении настройки max-endpoints-per-slice.

При создании сервиса с использованием селекторов EndpointSlices создаются и обновляются автоматически, туда вносятся все IP-адреса подов, которые удовлетворяют условию. Также EndpointSlices можно создавать вручную (например, это может понадобиться, если у созданного пода вообще нет селекторов), что позволяет вносить в них не только адреса подов, но и адреса других сервисов или даже внешних ресурсов (например, база данных за пределами кластера).

Важно понимать, что ни EndpointSlices, ни сами сервисы не занимаются отправкой трафика на поды. Эта обязанность ложится на плечи kube-proxy. Этот прокси, используя EndpointSlices, как источник правды, преобразует указанные там связи в сетевые правила и обеспечивает их выполнение на каждой ноде кластера. Сам сервис же в этом случае выступает такой же конечной точкой, как и поды.

![](https://miro.medium.com/v2/resize:fit:700/1*wJ0f1ZmHilwHiUzgPfE7mg.png)

Изображение взято из официальной документации kubernetes.io

**Service-to-External**
-----------------------

Итак, у нас есть сервис. По умолчанию сервис, а значит и все поды за ним, доступен только внутри кластера. Но гораздо чаще возникает ситуация, когда необходимо сделать приложение доступным не только для ресурсов в Kubernetes, но и для внешних приложений/пользователей. Сделать это можно несколькими способами.

Первый способ подходит, если ваш кластер Kubernetes рсполагается в облаке, которое предоставляет возможность создать внешний для кластера балансировщик нагрузки. В таком случае сервис можно “прицепить” к балансировщику: все запросы, которые на него приходят, будут перенаправляться на созданный сервис, а затем уже — к подам. Для этого при создании сервиса необходимо указать для него тип Load Balancer.

```
apiVersion: v1  
kind: Service  
metadata:  
  name: my-service  
spec:  
  selector:  
    app.kubernetes.io/name: MyApp  
  ports:  
    \- protocol: TCP  
      port: 80  
      targetPort: 9376  
  type: LoadBalancer
```

Этот манифест асинхронно создаст сервис my-service и балансировщик нагрузки. Для сервиса назначается не только внутренний Cluster-IP, но еще и External-IP — адрес того самого созданного балансировщика.

Второй способ сделать ваше приложение доступным для внешних пользователей — это использование ресурса Ingress. Этот ресурс может предоставлять сервисам URL-адреса, доступные извне, балансировать нагрузку, отключать SSL / TLS и предоставлять виртуальный хостинг на основе имен. Однако, его основным ограничением является то, что он работает только с HTTP и HTTPS трафиком. Если необходимо предоставить доступ к другим портам и протоколам, нужно выбрать другой способ.

![](https://miro.medium.com/v2/resize:fit:683/1*n_KNAWELUupV0SN85pcqGA.png)

Изображение взято из официальной документации kubernetes.io

Манифест простейшего Ингресс будет выглядеть следующим образом:

```
apiVersion: networking.k8s.io/v1  
kind: Ingress  
metadata:  
  name: minimal-ingress  
spec:  
  ingressClassName: nginx  
  rules:  
  \- http:  
      paths:  
      \- path: /testpath  
        pathType: Prefix  
        backend:  
          service:  
            name: test  
            port:  
              number: 80
```

Как видно, манифест содержит в себе имя ресурса, класс и набор правил, которые соединяют запросы с сервисом внутри кластера. По умолчанию правила применяются ко всем хостам, но можно и указать имя или IP-адрес, которым необходимо ограничиться.

Ингресс работает с помощью другого ресурса — Ingress Controller. Здесь та же ситуация, что и с EndpointSlices. Ingress — это набор правил для управления трафиком, а Ingress Controller — под (в некоторых случаях набор подов), который эти правила реализует. Контроллеры бывают разных типов, от которых зависит принцип их работы, на разбор этих типов — полноценная тема для отдельной статьи, поэтому мы не будем на этом останавливаться.

Еще один вариант — это Gateway API. Это open-source решение, которое предлагает набор ресурсов для управление внешним доступом в Kubernetes. По сравнению с Ingress Gateway API дает большую гибкость настроек и предоставляет доступ к настройкам, которых изначально нет в Kubernetes. Тем не менее, это самый сложный вариант из описанных в этой статье.

В первую очередь необходимо убедиться, что ваш дистрибутив Kubernetes поддерживает Gateway API. Это стороннее решение, так что не всегда оно входит в дистрибутив по умолчанию, и может понадобиться скачать дополнительные компоненты.

Затем нужно будет создать 3 объекта: GatewayClass, Gateway, HTTPRoute и/или TCPRoute.

GatewayClass — это ресурс, который определяет класс конкретного типа шлюза (например, HTTP или TCP) и его параметры конфигурации. Он может быть использован для определения различных типов шлюзов с различными настройками. Это, по факту, шаблон и набор настроек, который реализуется уже конкретными экземплярами — Gateway. Это основной ресурс, В нем указывается ссылка на GatewayClass, определяются службы, порты и другие параметры. HTTPRoute и TCPRoute определяют правила маршрутизации для HTTP и TCP трафика соответственно. Они позволяют настраивать маршруты на основе хоста, пути URL, методов HTTP и других параметров.

![](https://miro.medium.com/v2/resize:fit:576/1*t8vSJBAl258Sz0RTdD0a3w.png)

Изображение взято из официальной документации [gateway-api.sigs.k8s.io](https://gateway-api.sigs.k8s.io/)

После создания всех необходимых ресурсов, в дело вступает контроллер Gateway API. Когда создаются или изменяются ресурсы GatewayClass, HTTPRoute или TCPRoute, контроллер обнаруживает эти изменения и настраивает соответствующие шлюзы для обработки входящего трафика. По сути, именно контроллер является тем ресурсом, что отвечает за маршрутизацию трафика, а все остальные ресурсы, упомянутые выше — это источники информации контроллера.

Ну и, под конец, следует упомянуть, что есть возможность сделать сервис доступным не всем адресам в сети, а только с машины, где ведется работа с Kubernetes. Это удобно для дебага или когда приложение создается в учебных целях. Речь идет про всем известный проброс портов. Чтобы пробросить порт на локальную машину, необходимо выполнить следующую команду:

```
kubectl port-forward service/my-service 80:8080
```

Здесь my-service — это имя сервиса, который мы хотим сделать доступным на локальном сервере, 8080 — порт, открытый у этого сервиса, а 80 — порт на локальном хосте, все запросы на который мы хотим перенаправлять внутрь кластера. После выполнения этой команды сервис станет доступен по адресу localhost:80.

**Заключение**
--------------

Надеюсь, эта статья помогла вам разобраться в том, как взаимодействуют между собой различные ресурсы в Kubernetes. Тема сети в кластере очень обширная, и ее невозможно охватить целиком за одну небольшую статью, но полученной информации должно быть достаточно, чтобы начать разворачивать в кластере собственные приложения и понемногу погружаться в работу Kubernetes.